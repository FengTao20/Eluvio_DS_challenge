{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This repository studies the relation between upvotes and strings in the title, i.e., my goal is to predict the number of subreddit Upvotes based on the title of a post with a simple Linear regression model.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from dask import dataframe as dd  ## pip install dask \n",
    "import time\n",
    "import os\n",
    "from dask.distributed import Client\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import textwrap\n",
    "\n",
    "import glob\n",
    "import csv\n",
    "import random\n",
    "\n",
    "import statistics\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Clean up RAM\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07651892490684986 GB\n"
     ]
    }
   ],
   "source": [
    "#### Get the size of the data\n",
    "print(os.path.getsize('Eluvio_DS_Challenge.csv')/1024/1024/1024 , \"GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_created</th>\n",
       "      <th>date_created</th>\n",
       "      <th>up_votes</th>\n",
       "      <th>down_votes</th>\n",
       "      <th>title</th>\n",
       "      <th>over_18</th>\n",
       "      <th>author</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=2</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>int64</td>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>bool</td>\n",
       "      <td>object</td>\n",
       "      <td>object</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: from-delayed, 6 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "              time_created date_created up_votes down_votes   title over_18  author category\n",
       "npartitions=2                                                                               \n",
       "                     int64       object    int64      int64  object    bool  object   object\n",
       "                       ...          ...      ...        ...     ...     ...     ...      ...\n",
       "                       ...          ...      ...        ...     ...     ...     ...      ...\n",
       "Dask Name: from-delayed, 6 tasks"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### dask load dataset\n",
    "dask_df = dd.read_csv('Eluvio_DS_Challenge.csv')\n",
    "dask_df ## check the dataframe structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### relation between dask and pd, by adding \".compute()\"\n",
    "type(dask_df.partitions[0].compute()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "509236\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    394261\n",
       "1    114975\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Check partitions\n",
    "print(len(dask_df.index))  ## total rows (not including the title) \n",
    "##print(dask_df.columns) \n",
    "##dask_df.head()  ## print out samples\n",
    "dask_df.map_partitions(len).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### filter out all rows containing one or more missing values\n",
    "##df = dask_df.dropna()  \n",
    "df = dask_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert titles into images (this step may take a few hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Hyperparameters for image generation\n",
    "fontname = \"calibri.ttf\" #### font family\n",
    "fontsize = 11   \n",
    "font = ImageFont.truetype(fontname, fontsize)\n",
    "Max_W, Max_H = 160, 150\n",
    "\n",
    "gap = 10000   ## row limits for sub csv file\n",
    "\n",
    "#### function for saving csv file\n",
    "def write_csv_feature(data): ## no space between two lines\n",
    "    with open('dataset.csv', 'a', newline='') as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in range(1):\n",
    "    index = random.randint(0, len(df['title'])-1)\n",
    "    text = df['title'].compute().iloc[index]\n",
    "    text = \" \".join(text.split())  ## remove unnessary blanks\n",
    "    para = textwrap.wrap(text, width=30)  ## break the long line\n",
    "    img = Image.new('L', (Max_W, Max_H), \"white\")  ## modes 'L', 'RGB'\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    current_h, pad = 5, 2 ## text starting position\n",
    "    for line in para:\n",
    "        w, h = draw.textsize(line, font=font)\n",
    "        draw.text(((Max_W - w) / 2, current_h), line, fill=\"black\",font=font)\n",
    "        current_h += h + pad\n",
    "    img.show() \n",
    "    img = img.resize((80,75))\n",
    "    img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./Titles1/dataset0.csv is generated.\n",
      "File ./Titles1/dataset20.csv is generated.\n",
      "File ./Titles1/dataset40.csv is generated.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists('Titles1'):\n",
    "        os.makedirs('Titles1')\n",
    "for step in range(len(df.index)//gap+1): \n",
    "    filename = './Titles1/dataset'+str(step)+'.csv'\n",
    "    \n",
    "    for i in range(gap*step, min(gap*(step+1), len(df.index))): #len(df.index)\n",
    "        #start = time.time() \n",
    "        #if i%1000==0:\n",
    "        #    print(i)\n",
    "        text = df['title'].compute().iloc[i]\n",
    "        text = \" \".join(text.split())  ## remove unnessary blanks\n",
    "        para = textwrap.wrap(text, width=30)  ## break the long line\n",
    "        img = Image.new('L', (Max_W, Max_H), \"white\")  ## modes 'L', 'RGB'\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        current_h, pad = 5, 2 ## starting position\n",
    "        for line in para:\n",
    "            w, h = draw.textsize(line, font=font)\n",
    "            draw.text(((Max_W - w) / 2, current_h), line, fill=\"black\", font=font)\n",
    "            current_h += h + pad\n",
    "        if not os.path.exists('Titles'):\n",
    "            os.makedirs('Titles')    \n",
    "        #img.save(\"./Titles/image_\"+str(i)+\".png\")  ## If you want to save the images\n",
    "\n",
    "        pixels = np.array(img.resize((80,75))).flatten()  ## reduce size\n",
    "        #print(pixels)\n",
    "        write_csv_feature(filename, pixels/255)  ## write to csv file continuously \n",
    "\n",
    "        #end = time.time()\n",
    "        #print('Time: ', end-start, '\\n')\n",
    "    \n",
    "    if step%20 == 0:    \n",
    "        print('File {} is generated.'.format(filename))\n",
    "    ## the dataset file is a huge dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A simple linear regression model using sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Incremental Learning with sklearn: partial_fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0 is done!\n",
      "\n",
      "Step 20 is done!\n",
      "\n",
      "Step 40 is done!\n",
      "\n",
      "1.3289048032230215e+24\n",
      "1.3029815089016052e+24\n",
      "1.313068357408645e+24\n",
      "1.3168499244503483e+24\n",
      "1.3182448831993055e+24\n",
      "1.3345570678429843e+24\n",
      "1.3261920267136884e+24\n",
      "1.3087975104619275e+24\n",
      "1.326595836295427e+24\n",
      "1.3139430539595557e+24\n",
      "1.3540806730019007e+24\n",
      "1.308798087204283e+24\n",
      "1.3366258287810967e+24\n",
      "1.3317082306242103e+24\n",
      "1.3469568669446417e+24\n",
      "1.3345091519160095e+24\n",
      "1.316783680819574e+24\n",
      "1.331051281657633e+24\n",
      "1.3199601789657164e+24\n",
      "1.309571789455776e+24\n",
      "1.3155857766290906e+24\n",
      "1.3070318388921715e+24\n",
      "1.3317881863187894e+24\n",
      "1.3336799708921306e+24\n",
      "1.33364831493215e+24\n",
      "1.307638062059872e+24\n",
      "1.306380386892128e+24\n",
      "1.315401934551662e+24\n",
      "1.3346162367092735e+24\n",
      "1.3155148516387748e+24\n",
      "1.3354299383592063e+24\n",
      "1.2903560611586978e+24\n",
      "1.3245894931966984e+24\n",
      "1.3101738482423917e+24\n",
      "1.3067266803372542e+24\n",
      "1.306589239626316e+24\n",
      "1.3237621684508654e+24\n",
      "1.3119279098588633e+24\n",
      "1.3226586119657984e+24\n",
      "1.316395345773604e+24\n",
      "1.3135681522341608e+24\n",
      "1.30648828829033e+24\n",
      "1.3243244326031442e+24\n",
      "1.300134081119976e+24\n",
      "1.32210427380605e+24\n",
      "1.309574006255372e+24\n",
      "1.3159373519299948e+24\n",
      "1.3222644908150265e+24\n",
      "1.2952468489943235e+24\n",
      "1.2942103846003606e+24\n",
      "1.2910636701735062e+24\n",
      "Average mse:  1.3181370897869672e+24\n",
      "Std mse:  1.3753621370218876e+22\n",
      "std:  dd.Scalar<series-..., dtype=float64>\n",
      "mean:  dd.Scalar<series-..., dtype=float64>\n"
     ]
    }
   ],
   "source": [
    "lr = SGDRegressor()\n",
    "for step in range(len(df.index)//gap+1):\n",
    "    #print('step: ', step)\n",
    "    filename = './Titles1/dataset'+str(step)+'.csv'\n",
    "    feature = pd.read_csv(filename)\n",
    "    label = df[\"up_votes\"].compute().iloc[gap*step:min(gap*(step+1), len(df.index))-1]\n",
    "    X, X_t, y, y_t = train_test_split(feature, label, test_size=0.2, random_state=1)\n",
    "    test_data = pd.DataFrame.from_records(X_t)\n",
    "    test_data.to_csv('./Titles1/testing'+str(step)+'.csv', header=False, index=False)\n",
    "    with open(\"./Titles1/testing_label\"+str(step)+\".csv\",\"w\") as f:\n",
    "        wr = csv.writer(f, delimiter=\"\\n\")\n",
    "        wr.writerow(y_t)\n",
    "    lr.partial_fit(X, y)  ## not overwrite the model's previous parameters\n",
    "    if step%20 == 0:\n",
    "        print('Step {} is done!\\n'.format(step))\n",
    "\n",
    "mse_list = []\n",
    "for step in range(len(df.index)//gap+1):\n",
    "    X_T = pd.read_csv('./Titles1/testing'+str(step)+'.csv')\n",
    "    X_T = pd.DataFrame(X_T)\n",
    "    predictions = lr.predict(X_T)\n",
    "    #print('predictions: ', predictions[0:10])\n",
    "    y_T = pd.read_csv(\"./Titles1/testing_label\"+str(step)+\".csv\")\n",
    "    y_T = pd.DataFrame(y_T)\n",
    "    #print('the true upvote: ', y_T[0:10])\n",
    "    mse = mean_squared_error(predictions, y_T)\n",
    "    print(mse)\n",
    "    mse_list.append(mse)\n",
    "\n",
    "print('Average mse: ', statistics.mean(mse_list))\n",
    "print('Std mse: ', statistics.stdev(mse_list))\n",
    "\n",
    "print('std: ', df['up_votes'].std())\n",
    "print('mean: ', df['up_votes'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The given Eluvio_DS_Challenge.csv file has a 112+/-542 upvotes. However, our model achieves a bad result. The potential reasons for this failure are:\n",
    "1. The SGDRegressor Model does not fit our dataset.\n",
    "2. The model may be underfitted as both training acc and testing acc are low.\n",
    "3. The training sample's feature dimension is not appropriate. In our experiment, its dimension is 6000 (i.e., 80*75).\n",
    "4. The title is not the only factor that determines the upvotes.\n",
    "\n",
    "Further improvement can be made by (1) including the author and submission time, (2) introducing more advance machine learning tools, say deep neural network, to approximate the nonlinear relation between upvotes and titles, (3) convolutional neural network can be implemented to handle the image input. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://github.com/shachi01/dask_in_python_ml/blob/master/efficient_read_csv.ipynb\n",
    "2. https://stackoverflow.com/questions/17856242/how-to-convert-a-string-to-an-image \n",
    "3. https://towardsdatascience.com/the-art-of-the-upvote-using-nlp-to-predict-upvotes-based-on-headline-458408be3c73"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
